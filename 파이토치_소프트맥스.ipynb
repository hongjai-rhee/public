{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "파이토치 소프트맥스.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5MvUFF0kIZtRL6ZutYotU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongjai-rhee/public/blob/master/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Ora49rGPUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch; import torch.nn as nn ;import torch.nn.functional as F\n",
        "import torch.optim as optim ;from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable ;from torch import nn, tensor, max; import numpy as np\n",
        "\n",
        "# Cross entropy example\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26RWun8EKUgB",
        "colab_type": "text"
      },
      "source": [
        "# 원 핫코드를 사용한 크로스 엔트로피 손실 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA5iTDdzGZSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02f930c6-cf44-4df7-801d-9ad4014f1b20"
      },
      "source": [
        "Y = np.array([1, 0, 0])\n",
        "print(Y)\n",
        "Y_pred1 = np.array([0.705385, 0.259496, 0.035119])\n",
        "print(\"loss1 = \", np.sum(-Y * np.log(Y_pred1)))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0]\n",
            "loss1 =  0.3490115259370414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSJovnFCKFPw",
        "colab_type": "text"
      },
      "source": [
        "# 파이토치의 CrossEntropy 손실함수는 softmax 변환을 자동으로 처리한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoDIF3xpGhHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f8de8d18-8898-420e-e988-119e14026cba"
      },
      "source": [
        "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = tensor([0], requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 1 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = tensor([[2.0, 1.0, -1.0]])\n",
        "print(Y)\n",
        "l1 = loss(Y_pred1, Y)\n",
        "\n",
        "print(\"PyTorch Loss1 = \", l1.data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0])\n",
            "PyTorch Loss1 =  tensor(0.3490)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPAXfxWDKgsI",
        "colab_type": "text"
      },
      "source": [
        "# 따라서 Y는 원핫코드가 아니라 0~K 의 정수 스칼라가 된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjSCrUa3I2Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef44937f-7960-4f4a-8a98-e064144e0a49"
      },
      "source": [
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "\n",
        "Y = tensor([2, 0, 1], requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 2 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "\n",
        "Y_pred1 = tensor([[ 2.9,  1.9, 0.5],\n",
        "                  [-1.3,  5.2, 3.0],\n",
        "                  [ 0.5,  3.2, 4.4]])\n",
        "\n",
        "\n",
        "l1 = loss(Y_pred1, Y)\n",
        "\n",
        "print(\"Loss1 = \", l1.data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss1 =  tensor(3.6209)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}